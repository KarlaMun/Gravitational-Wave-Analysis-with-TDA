{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gravitational wave detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Import the NumPy library for numerical operations\n",
    "from pathlib import Path # Import the Path class from the pathlib module to handle file system paths\n",
    "from scipy.stats import norm # Import the norm class from scipy.stats for statistical functions\n",
    "\n",
    "# Poner comentarios en cada linea de que significa cada cosa\n",
    "# En alguna parte se asegura que los datos esten balanceados.\n",
    "# Tarea: Generar datos con imbalance (75 se√±al, 25 ruido) (25-75) (90-10) (10-90)\n",
    "\n",
    "# Define the main function `make_gravitational_waves`\n",
    "def make_gravitational_waves(\n",
    "    path_to_data: Path, # Path to the directory containing the data\n",
    "    n_signals: int = 30, # Number of signals to generate\n",
    "    downsample_factor: int = 2, # Factor by which to downsample the signals\n",
    "    Rcoef: float = 0.5, # Signal-to-noise ratio (SNR) coefficient\n",
    "    perc_signal: float = 0.5, # Data partitioning factor\n",
    "        ):\n",
    "    def padrand(V, n, kr):\n",
    "        cut = np.random.randint(n) # Generate a random integer to determine the split point for padding\n",
    "        rand1 = np.random.randn(cut) # Create random noise for the first part of the padding\n",
    "        rand2 = np.random.randn(n - cut) # Create random noise for the second part of the padding\n",
    "        \n",
    "        # Concatenate the first padding, the input signal `V`, and the second padding\n",
    "        # Scale the padding by the factor `kr`\n",
    "        out = np.concatenate((rand1 * kr, V, rand2 * kr))\n",
    "        return out\n",
    "\n",
    "    Npad = 50  # number of padding points on either side of the vector\n",
    "    gw = np.load(\"../data/gravitational_wave_signals.npy\") # Load data\n",
    "    Norig = len(gw[\"data\"][0]) # Get the original number of data points in each signal\n",
    "    Ndat = len(gw[\"signal_present\"]) # Get the total number of signals in the dataset todo es uno\n",
    "    N = int(Norig / downsample_factor) # Calculate the number of data points after downsampling\n",
    "\n",
    "    # Initialize lists to store noise coefficients and SNR coefficients\n",
    "    ncoeff = []\n",
    "    Rcoeflist = []\n",
    "\n",
    "    # Loop through the number of signals to generate noise coefficients and SNR coefficients\n",
    "    for j in range(n_signals):\n",
    "        # Calculate the noise coefficient based on the R coefficient\n",
    "        ncoeff.append(10 ** (-19) * (1 / Rcoef))\n",
    "        # Append the corresponding R coefficient to the list\n",
    "        Rcoeflist.append(Rcoef)\n",
    "\n",
    "    # Initialize variables\n",
    "    noisy_signals = []\n",
    "    gw_signals = []\n",
    "    k = 0\n",
    "    labels = np.zeros(n_signals)\n",
    "\n",
    "    # Loop through the number of signals to generate noisy signals and labels\n",
    "    for j in range(n_signals):\n",
    "        # Select a signal from the dataset and downsample it\n",
    "        signal = gw[\"data\"][j % Ndat][range(0, Norig, downsample_factor)]\n",
    "        \n",
    "        # Randomly decide if the signal is present (1) or absent (0)\n",
    "        crit_val = norm.ppf(perc_signal) # Critical value for the normal distributio\n",
    "        sigp = int((np.random.randn() < crit_val))\n",
    "        \n",
    "        # Generate random noise scaled by the noise coefficient\n",
    "        noise = ncoeff[j] * np.random.randn(N)\n",
    "        \n",
    "        # Assign the label based on whether the signal is present\n",
    "        labels[j] = sigp\n",
    "        \n",
    "        # If the signal is present, add it to the noise and pad the result\n",
    "        if sigp == 1:\n",
    "            rawsig = padrand(signal + noise, Npad, ncoeff[j])\n",
    "            \n",
    "            # Ensure at least one signal is present in the dataset\n",
    "            if k == 0:\n",
    "                k = 1\n",
    "        else:\n",
    "            # If the signal is absent, pad only the noise\n",
    "            rawsig = padrand(noise, Npad, ncoeff[j])\n",
    "        \n",
    "        # Append the padded noisy signal to the list\n",
    "        noisy_signals.append(rawsig.copy())\n",
    "        \n",
    "        # Append the original signal to the list\n",
    "        gw_signals.append(signal)\n",
    "    \n",
    "    # Return the generated noisy signals, original signals, and labels\n",
    "    return noisy_signals, gw_signals, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 50-50\n",
    "# generate and get data\n",
    "R = 0.50 # Maximum signal-to-noise ratio (SNR) coefficient\n",
    "n_signals = 100 # Number of signals to generate\n",
    "DATA = Path(\".\") # Path to the directory containing the data\n",
    "dataPartition = 0.5 # Data partitioning factor\n",
    "noisy_signals_50_50, gw_signals_50_50, labels_50_50 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_50_50 = np.array(noisy_signals_50_50) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_50_50 = np.array(gw_signals_50_50) # Convert the list of original signals to a NumPy array\n",
    "labels_50_50 = np.array(labels_50_50) # Convert the labels list to a NumPy array\n",
    "\n",
    "# Dataset 25-75\n",
    "dataPartition = 0.25 # Data partitioning factor\n",
    "noisy_signals_25_75, gw_signals_25_75, labels_25_75 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_25_75 = np.array(noisy_signals_25_75) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_25_75 = np.array(gw_signals_25_75) # Convert the list of original signals to a NumPy array\n",
    "labels_25_75 = np.array(labels_25_75) # Convert the labels list to a NumPy array\n",
    "\n",
    "# Dataset 75-25\n",
    "dataPartition = 0.75 # Data partitioning factor\n",
    "noisy_signals_75_25, gw_signals_75_25, labels_75_25 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_75_25 = np.array(noisy_signals_75_25) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_75_25 = np.array(gw_signals_75_25) # Convert the list of original signals to a NumPy array\n",
    "labels_75_25 = np.array(labels_75_25) # Convert the labels list to a NumPy array\n",
    "\n",
    "# Dataset 10-90\n",
    "dataPartition = 0.10 # Data partitioning factor\n",
    "noisy_signals_10_90, gw_signals_10_90, labels_10_90 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_10_90 = np.array(noisy_signals_10_90) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_10_90 = np.array(gw_signals_10_90) # Convert the list of original signals to a NumPy array\n",
    "labels_10_90 = np.array(labels_10_90) # Convert the labels list to a NumPy array\n",
    "\n",
    "# Dataset 90-10\n",
    "dataPartition = 0.90 # Data partitioning factor\n",
    "noisy_signals_90_10, gw_signals_90_10, labels_90_10 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_90_10 = np.array(noisy_signals_90_10) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_90_10 = np.array(gw_signals_90_10) # Convert the list of original signals to a NumPy array\n",
    "labels_90_10 = np.array(labels_90_10) # Convert the labels list to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.0\n",
      "30.0\n",
      "79.0\n",
      "7.0\n",
      "89.0\n"
     ]
    }
   ],
   "source": [
    "print(labels_50_50.sum()) # Print the sum of labels to check the number of signals present\n",
    "print(labels_25_75.sum()) # Print the sum of labels to check the number of signals present\n",
    "print(labels_75_25.sum()) # Print the sum of labels to check the number of signals present\n",
    "print(labels_10_90.sum()) # Print the sum of labels to check the number of signals present\n",
    "print(labels_90_10.sum()) # Print the sum of labels to check the number of signals present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4048, 50)\n",
      "100\n",
      "(100, 4146)\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.34027218e-19, -3.58957443e-19,  1.00876066e-19, ...,\n",
       "        -2.68485533e-19,  1.47052326e-19,  2.45399686e-19],\n",
       "       [ 1.69100204e-19,  2.96094893e-19, -4.29817537e-19, ...,\n",
       "         2.28681812e-19, -2.45026725e-20, -4.19326339e-20],\n",
       "       [-3.58957443e-19,  1.00876066e-19,  5.41672429e-20, ...,\n",
       "         1.47052326e-19,  2.45399686e-19,  3.32039855e-19],\n",
       "       ...,\n",
       "       [-3.38283166e-19, -1.62368914e-19,  1.27224932e-19, ...,\n",
       "        -2.12972656e-19,  1.22209308e-19,  1.25598404e-19],\n",
       "       [-1.06045012e-19, -3.22780352e-19,  2.43646126e-20, ...,\n",
       "         5.45488392e-20, -1.04393620e-19, -4.62985828e-19],\n",
       "       [-1.62368914e-19,  1.27224932e-19, -3.05822748e-19, ...,\n",
       "         1.22209308e-19,  1.25598404e-19,  1.35458808e-19]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noisy_signals_50_50[0])\n",
    "time_delay = 2\n",
    "dimension = 50\n",
    "from gtda.time_series import TakensEmbedding\n",
    "TE = TakensEmbedding(time_delay=time_delay, dimension=dimension)\n",
    "data = TE.fit_transform(noisy_signals_50_50)\n",
    "\n",
    "print(data.shape)\n",
    "print(len(data))\n",
    "print(noisy_signals_50_50.shape)\n",
    "print(len(noisy_signals_50_50))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;takensembedding&#x27;,\n",
       "                 TakensEmbedding(dimension=100, stride=2, time_delay=30)),\n",
       "                (&#x27;vietorisripspersistence&#x27;, VietorisRipsPersistence()),\n",
       "                (&#x27;amplitude&#x27;, Amplitude()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;takensembedding&#x27;,\n",
       "                 TakensEmbedding(dimension=100, stride=2, time_delay=30)),\n",
       "                (&#x27;vietorisripspersistence&#x27;, VietorisRipsPersistence()),\n",
       "                (&#x27;amplitude&#x27;, Amplitude()),\n",
       "                (&#x27;randomforestregressor&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TakensEmbedding</label><div class=\"sk-toggleable__content\"><pre>TakensEmbedding(dimension=100, stride=2, time_delay=30)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VietorisRipsPersistence</label><div class=\"sk-toggleable__content\"><pre>VietorisRipsPersistence()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Amplitude</label><div class=\"sk-toggleable__content\"><pre>Amplitude()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('takensembedding',\n",
       "                 TakensEmbedding(dimension=100, stride=2, time_delay=30)),\n",
       "                ('vietorisripspersistence', VietorisRipsPersistence()),\n",
       "                ('amplitude', Amplitude()),\n",
       "                ('randomforestregressor', RandomForestRegressor())])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtda.time_series import SlidingWindow\n",
    "from gtda.time_series import TakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import Amplitude\n",
    "from gtda.pipeline import make_pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "time_delay = 30\n",
    "dimension = 100\n",
    "\n",
    "TE = TakensEmbedding(time_delay=time_delay, dimension=dimension, stride=stride)\n",
    "VR = VietorisRipsPersistence() \n",
    "Ampl = Amplitude()\n",
    "RFR = RandomForestRegressor()\n",
    "pipe = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0244097638834049e-05"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_50_50 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_50_50.fit(noisy_signals_50_50, labels_50_50)\n",
    "pipe_50_50.score(noisy_signals_50_50, labels_50_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.904761904802932e-05"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_25_75 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_25_75.fit(noisy_signals_25_75, labels_25_75)\n",
    "pipe_25_75.score(noisy_signals_25_75, labels_25_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.424954792054848e-05"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_75_25 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_75_25.fit(noisy_signals_75_25, labels_75_25)\n",
    "pipe_75_25.score(noisy_signals_75_25, labels_75_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0107526881595348e-05"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_10_90 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_10_90.fit(noisy_signals_10_90, labels_10_90)\n",
    "pipe_10_90.score(noisy_signals_10_90, labels_10_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0001323799795711622"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_90_10 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_90_10.fit(noisy_signals_90_10, labels_90_10)\n",
    "pipe_90_10.score(noisy_signals_90_10, labels_90_10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
