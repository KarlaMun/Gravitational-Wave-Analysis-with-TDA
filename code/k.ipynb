{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gravitational wave detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Import the NumPy library for numerical operations\n",
    "from pathlib import Path # Import the Path class from the pathlib module to handle file system paths\n",
    "from scipy.stats import norm # Import the norm class from scipy.stats for statistical functions\n",
    "\n",
    "# Poner comentarios en cada linea de que significa cada cosa\n",
    "# En alguna parte se asegura que los datos esten balanceados.\n",
    "# Tarea: Generar datos con imbalance (75 señal, 25 ruido) (25-75) (90-10) (10-90)\n",
    "\n",
    "# Define the main function `make_gravitational_waves`\n",
    "def make_gravitational_waves(\n",
    "    path_to_data: Path, # Path to the directory containing the data\n",
    "    n_signals: int = 30, # Number of signals to generate\n",
    "    downsample_factor: int = 2, # Factor by which to downsample the signals\n",
    "    Rcoef: float = 0.5, # Signal-to-noise ratio (SNR) coefficient\n",
    "    perc_signal: float = 0.5, # Data partitioning factor\n",
    "        ):\n",
    "    def padrand(V, n, kr):\n",
    "        cut = np.random.randint(n) # Generate a random integer to determine the split point for padding\n",
    "        rand1 = np.random.randn(cut) # Create random noise for the first part of the padding\n",
    "        rand2 = np.random.randn(n - cut) # Create random noise for the second part of the padding\n",
    "        \n",
    "        # Concatenate the first padding, the input signal `V`, and the second padding\n",
    "        # Scale the padding by the factor `kr`\n",
    "        out = np.concatenate((rand1 * kr, V, rand2 * kr))\n",
    "        return out\n",
    "\n",
    "    Npad = 50  # number of padding points on either side of the vector\n",
    "    gw = np.load(\"../data/gravitational_wave_signals.npy\") # Load data\n",
    "    Norig = len(gw[\"data\"][0]) # Get the original number of data points in each signal\n",
    "    Ndat = len(gw[\"signal_present\"]) # Get the total number of signals in the dataset todo es uno\n",
    "    N = int(Norig / downsample_factor) # Calculate the number of data points after downsampling\n",
    "\n",
    "    # Initialize lists to store noise coefficients and SNR coefficients\n",
    "    ncoeff = []\n",
    "    Rcoeflist = []\n",
    "\n",
    "    # Loop through the number of signals to generate noise coefficients and SNR coefficients\n",
    "    for j in range(n_signals):\n",
    "        # Calculate the noise coefficient based on the R coefficient\n",
    "        ncoeff.append(10 ** (-19) * (1 / Rcoef))\n",
    "        # Append the corresponding R coefficient to the list\n",
    "        Rcoeflist.append(Rcoef)\n",
    "\n",
    "    # Initialize variables\n",
    "    noisy_signals = []\n",
    "    gw_signals = []\n",
    "    k = 0\n",
    "    labels = np.zeros(n_signals)\n",
    "\n",
    "    # Loop through the number of signals to generate noisy signals and labels\n",
    "    for j in range(n_signals):\n",
    "        # Select a signal from the dataset and downsample it\n",
    "        signal = gw[\"data\"][j % Ndat][range(0, Norig, downsample_factor)]\n",
    "        \n",
    "        # Randomly decide if the signal is present (1) or absent (0)\n",
    "        crit_val = norm.ppf(perc_signal) # Critical value for the normal distributio\n",
    "        sigp = int((np.random.randn() < crit_val))\n",
    "        \n",
    "        # Generate random noise scaled by the noise coefficient\n",
    "        noise = ncoeff[j] * np.random.randn(N)\n",
    "        \n",
    "        # Assign the label based on whether the signal is present\n",
    "        labels[j] = sigp\n",
    "        \n",
    "        # If the signal is present, add it to the noise and pad the result\n",
    "        if sigp == 1:\n",
    "            rawsig = padrand(signal + noise, Npad, ncoeff[j])\n",
    "            \n",
    "            # Ensure at least one signal is present in the dataset\n",
    "            if k == 0:\n",
    "                k = 1\n",
    "        else:\n",
    "            # If the signal is absent, pad only the noise\n",
    "            rawsig = padrand(noise, Npad, ncoeff[j])\n",
    "        \n",
    "        # Append the padded noisy signal to the list\n",
    "        noisy_signals.append(rawsig.copy())\n",
    "        \n",
    "        # Append the original signal to the list\n",
    "        gw_signals.append(signal)\n",
    "    \n",
    "    # Return the generated noisy signals, original signals, and labels\n",
    "    return noisy_signals, gw_signals, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 50-50\n",
    "# generate and get data\n",
    "R = 0.50 # Maximum signal-to-noise ratio (SNR) coefficient\n",
    "n_signals = 100 # Number of signals to generate\n",
    "DATA = Path(\".\") # Path to the directory containing the data\n",
    "dataPartition = 0.5 # Data partitioning factor\n",
    "noisy_signals_50_50, gw_signals_50_50, labels_50_50 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_50_50 = np.array(noisy_signals_50_50) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_50_50 = np.array(gw_signals_50_50) # Convert the list of original signals to a NumPy array\n",
    "labels_50_50 = np.array(labels_50_50) # Convert the labels list to a NumPy array\n",
    "\n",
    "# Dataset 25-75\n",
    "dataPartition = 0.25 # Data partitioning factor\n",
    "noisy_signals_25_75, gw_signals_25_75, labels_25_75 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_25_75 = np.array(noisy_signals_25_75) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_25_75 = np.array(gw_signals_25_75) # Convert the list of original signals to a NumPy array\n",
    "labels_25_75 = np.array(labels_25_75) # Convert the labels list to a NumPy array\n",
    "\n",
    "# Dataset 75-25\n",
    "dataPartition = 0.75 # Data partitioning factor\n",
    "noisy_signals_75_25, gw_signals_75_25, labels_75_25 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_75_25 = np.array(noisy_signals_75_25) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_75_25 = np.array(gw_signals_75_25) # Convert the list of original signals to a NumPy array\n",
    "labels_75_25 = np.array(labels_75_25) # Convert the labels list to a NumPy array\n",
    "\n",
    "# Dataset 10-90\n",
    "dataPartition = 0.10 # Data partitioning factor\n",
    "noisy_signals_10_90, gw_signals_10_90, labels_10_90 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_10_90 = np.array(noisy_signals_10_90) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_10_90 = np.array(gw_signals_10_90) # Convert the list of original signals to a NumPy array\n",
    "labels_10_90 = np.array(labels_10_90) # Convert the labels list to a NumPy array\n",
    "\n",
    "# Dataset 90-10\n",
    "dataPartition = 0.90 # Data partitioning factor\n",
    "noisy_signals_90_10, gw_signals_90_10, labels_90_10 = make_gravitational_waves(\n",
    "    path_to_data=DATA, n_signals=n_signals, Rcoef=R, perc_signal=dataPartition\n",
    ")\n",
    "noisy_signals_90_10 = np.array(noisy_signals_90_10) # Convert the list of noisy signals to a NumPy array\n",
    "gw_signals_90_10 = np.array(gw_signals_90_10) # Convert the list of original signals to a NumPy array\n",
    "labels_90_10 = np.array(labels_90_10) # Convert the labels list to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.0\n",
      "31.0\n",
      "75.0\n",
      "6.0\n",
      "89.0\n"
     ]
    }
   ],
   "source": [
    "print(labels_50_50.sum()) # Print the sum of labels to check the number of signals present\n",
    "print(labels_25_75.sum()) # Print the sum of labels to check the number of signals present\n",
    "print(labels_75_25.sum()) # Print the sum of labels to check the number of signals present\n",
    "print(labels_10_90.sum()) # Print the sum of labels to check the number of signals present\n",
    "print(labels_90_10.sum()) # Print the sum of labels to check the number of signals present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8144, 50)\n",
      "100\n",
      "(100, 8242)\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.38484381e-20,  5.00892720e-19, -3.68882873e-20, ...,\n",
       "        -7.10830301e-20, -4.51767246e-19, -1.00441488e-19],\n",
       "       [-2.68558970e-19,  1.47136405e-19,  2.53630913e-19, ...,\n",
       "         4.49784482e-20, -1.09226276e-19,  3.24602585e-20],\n",
       "       [ 5.00892720e-19, -3.68882873e-20,  1.34254817e-19, ...,\n",
       "        -4.51767246e-19, -1.00441488e-19, -7.18014334e-20],\n",
       "       ...,\n",
       "       [-1.47628102e-19, -9.70302848e-20,  3.34606202e-19, ...,\n",
       "         5.66656927e-19, -1.88403063e-19,  7.90906152e-20],\n",
       "       [-1.87465155e-19,  2.12781333e-19,  2.04979125e-19, ...,\n",
       "        -1.27353305e-19,  1.89767329e-19, -4.66810392e-21],\n",
       "       [-9.70302848e-20,  3.34606202e-19, -9.31628995e-20, ...,\n",
       "        -1.88403063e-19,  7.90906152e-20,  2.33612470e-19]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noisy_signals_50_50[0])\n",
    "time_delay = 2\n",
    "dimension = 50\n",
    "from gtda.time_series import TakensEmbedding\n",
    "TE = TakensEmbedding(time_delay=time_delay, dimension=dimension)\n",
    "data = TE.fit_transform(noisy_signals_50_50)\n",
    "\n",
    "print(data.shape)\n",
    "print(len(data))\n",
    "print(noisy_signals_50_50.shape)\n",
    "print(len(noisy_signals_50_50))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;takensembedding&#x27;,\n",
       "                 TakensEmbedding(dimension=100, stride=5, time_delay=30)),\n",
       "                (&#x27;vietorisripspersistence&#x27;, VietorisRipsPersistence()),\n",
       "                (&#x27;amplitude&#x27;, Amplitude()),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=37))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;takensembedding&#x27;,\n",
       "                 TakensEmbedding(dimension=100, stride=5, time_delay=30)),\n",
       "                (&#x27;vietorisripspersistence&#x27;, VietorisRipsPersistence()),\n",
       "                (&#x27;amplitude&#x27;, Amplitude()),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=37))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TakensEmbedding</label><div class=\"sk-toggleable__content\"><pre>TakensEmbedding(dimension=100, stride=5, time_delay=30)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VietorisRipsPersistence</label><div class=\"sk-toggleable__content\"><pre>VietorisRipsPersistence()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Amplitude</label><div class=\"sk-toggleable__content\"><pre>Amplitude()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=37)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('takensembedding',\n",
       "                 TakensEmbedding(dimension=100, stride=5, time_delay=30)),\n",
       "                ('vietorisripspersistence', VietorisRipsPersistence()),\n",
       "                ('amplitude', Amplitude()),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(criterion='entropy', random_state=37))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtda.time_series import SlidingWindow\n",
    "from gtda.time_series import TakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import Amplitude\n",
    "from gtda.pipeline import make_pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "time_delay = 30\n",
    "dimension = 100\n",
    "stride = 5\n",
    "\n",
    "TE = TakensEmbedding(time_delay=time_delay, dimension=dimension, stride=stride)\n",
    "VR = VietorisRipsPersistence() \n",
    "Ampl = Amplitude()\n",
    "RFR = RandomForestClassifier(criterion=\"entropy\", random_state=37)\n",
    "pipe = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_50_50 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_50_50.fit(noisy_signals_50_50, labels_50_50)\n",
    "pipe_50_50.score(noisy_signals_50_50, labels_50_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        44\n",
      "         1.0       0.56      1.00      0.72        56\n",
      "\n",
      "    accuracy                           0.56       100\n",
      "   macro avg       0.28      0.50      0.36       100\n",
      "weighted avg       0.31      0.56      0.40       100\n",
      "\n",
      "[[ 0 44]\n",
      " [ 0 56]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristobal/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cristobal/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cristobal/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# pipe_50_50 metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred_50_50 = pipe_50_50.predict(noisy_signals_50_50)\n",
    "print(classification_report(labels_50_50, y_pred_50_50))\n",
    "print(confusion_matrix(labels_50_50, y_pred_50_50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_25_75 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_25_75.fit(noisy_signals_25_75, labels_25_75)\n",
    "pipe_25_75.score(noisy_signals_25_75, labels_25_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_75_25 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_75_25.fit(noisy_signals_75_25, labels_75_25)\n",
    "pipe_75_25.score(noisy_signals_75_25, labels_75_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_10_90 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_10_90.fit(noisy_signals_10_90, labels_10_90)\n",
    "pipe_10_90.score(noisy_signals_10_90, labels_10_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m pipe_90_10 = make_pipeline(TE, VR, Ampl, RFR)\n\u001b[32m      2\u001b[39m pipe_90_10.fit(noisy_signals_90_10, labels_90_10)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mpipe_90_10\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_signals_90_10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_90_10\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/gtda/pipeline.py:443\u001b[39m, in \u001b[36mPipeline.score\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    441\u001b[39m         Xt, yr = transform.transform_resample(Xt, yr)\n\u001b[32m    442\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m         Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m score_params = {}\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/sklearn/utils/_set_output.py:157\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    160\u001b[39m         return_tuple = (\n\u001b[32m    161\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    162\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    163\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/gtda/homology/simplicial.py:302\u001b[39m, in \u001b[36mVietorisRipsPersistence.transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    298\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    299\u001b[39m X = check_point_clouds(X, accept_sparse=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    300\u001b[39m                        distance_matrices=\u001b[38;5;28mself\u001b[39m._is_precomputed)\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m Xt = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ripser_diagram\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m Xt = _postprocess_diagrams(\n\u001b[32m    306\u001b[39m     Xt, \u001b[33m\"\u001b[39m\u001b[33mripser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._homology_dimensions, \u001b[38;5;28mself\u001b[39m.infinity_values_,\n\u001b[32m    307\u001b[39m     \u001b[38;5;28mself\u001b[39m.reduced_homology\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/joblib/parallel.py:1985\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1983\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1984\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1985\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/joblib/parallel.py:1913\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1911\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1913\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/gtda/homology/simplicial.py:177\u001b[39m, in \u001b[36mVietorisRipsPersistence._ripser_diagram\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ripser_diagram\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     Xdgms = \u001b[43mripser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_max_homology_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_edge_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoeff\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcoeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric_params\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetric_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollapse_edges\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollapse_edges\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mdgms\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Xdgms\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/gph/python/ripser_interface.py:618\u001b[39m, in \u001b[36mripser_parallel\u001b[39m\u001b[34m(X, maxdim, thresh, coeff, metric, metric_params, nearest_neighbors_params, weights, weight_params, collapse_edges, n_threads, return_generators)\u001b[39m\n\u001b[32m    616\u001b[39m     diagonal = np.diagonal(dm).astype(np.float32)\n\u001b[32m    617\u001b[39m     DParam = squareform(dm, checks=\u001b[38;5;28;01mFalse\u001b[39;00m).astype(np.float32)\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m     res = \u001b[43m_compute_ph_vr_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDParam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiagonal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mcoeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_generators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[38;5;66;03m# Unwrap persistence diagrams\u001b[39;00m\n\u001b[32m    622\u001b[39m \u001b[38;5;66;03m# Barcodes must match the inner type of C++ core filtration value.\u001b[39;00m\n\u001b[32m    623\u001b[39m \u001b[38;5;66;03m# We call a method from the bindings that returns the barcodes as\u001b[39;00m\n\u001b[32m    624\u001b[39m \u001b[38;5;66;03m# numpy arrays with np.float32 type\u001b[39;00m\n\u001b[32m    625\u001b[39m dgms = res.births_and_deaths_by_dim()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gravitational_wave_analysis/lib/python3.12/site-packages/gph/python/ripser_interface.py:40\u001b[39m, in \u001b[36m_compute_ph_vr_dense\u001b[39m\u001b[34m(DParam, diagonal, maxHomDim, thresh, coeff, n_threads, return_generators)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute_ph_vr_dense\u001b[39m(DParam, diagonal, maxHomDim, thresh=-\u001b[32m1\u001b[39m, coeff=\u001b[32m2\u001b[39m,\n\u001b[32m     38\u001b[39m                          n_threads=\u001b[32m1\u001b[39m, return_generators=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coeff == \u001b[32m2\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         ret = \u001b[43mgph_ripser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrips_dm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDParam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiagonal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxHomDim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_generators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     43\u001b[39m         ret = gph_ripser_coeff.rips_dm(DParam, diagonal, coeff, maxHomDim,\n\u001b[32m     44\u001b[39m                                        thresh, n_threads, return_generators)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "pipe_90_10 = make_pipeline(TE, VR, Ampl, RFR)\n",
    "pipe_90_10.fit(noisy_signals_90_10, labels_90_10)\n",
    "pipe_90_10.score(noisy_signals_90_10, labels_90_10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gravitational_wave_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
